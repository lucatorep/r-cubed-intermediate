{
  "hash": "e6c3497ab8f63818fca8f5a0857d8b8c",
  "result": {
    "markdown": "# Save time, don't repeat yourself: Using functionals {#sec-functionals}\n\n\n\n\n\nWe will continue covering the \"*Workflow*\" block in\n@fig-overview-workflow.\n\n![Section of the overall workflow we will be\ncovering.](/images/overview-workflow.svg){#fig-overview-workflow}\n\n::: {.callout-note appearance=\"minimal\" collapse=\"true\"}\n## Instructor note\n\nBriefly go over the bigger picture (found in the introduction section)\nand remind everyone the 'what' and 'why' of what we are doing.\n:::\n\n## Learning objectives\n\n1.  Learn about and apply functional programming, vectorization, and\n    functionals within R.\n2.  Review the split-apply-combine technique and understand the link\n    with functional programming.\n3.  Apply functional programming to summarizing data and for using the\n    split-apply-combine technique.\n\n## Functional programming\n\n::: {.callout-note appearance=\"minimal\" collapse=\"true\"}\n## Instructor note\n\nGo over this section briefly by reinforcing what they read, especially\nreinforcing the concepts shown in the image. Make sure they understand\nthe concept of applying something to many things at once and that\nfunctionals are better coding patterns to use compared to loops. Doing\nthe code-along should also help reinforce this concept.\n\nAlso highlight that the resources appendix has some links for continued\nlearning for this and that the RStudio `{purrr}` cheatsheet is an\namazing resource to use.\n:::\n\n::: callout-note\n## Reading task: \\~15 minutes\n\nUnlike many other programming languages, R's primary strength and\napproach to programming is in functional programming. So what is it? It\nis programming that:\n\n-   Uses functions (like `function()`).\n-   Applies functions to vectors all at once (called\n    [vectorisation](https://bookdown.org/rdpeng/rprogdatascience/vectorized-operations.html)),\n    rather than one at a time.\n    -   Vectors are multiple items, like a sequence of numbers from 1 to\n        5, that are bundled together, for instance a column for body\n        weight in a dataset is a vector of numbers.\n-   Can use functions as input to other functions to then output a\n    vector (called a\n    [functional](https://adv-r.hadley.nz/functionals.html)).\n\nWe've already covered functions. You've definitely already used\nvectorization since it is one of R's big strengths. For instance,\nfunctions like `mean()`, `sd()`, `sum()` are vectorized in that you give\nthem a vector of numbers and they do something to all the values in the\nvector at once. In vectorized functions, you can give the function an\nentire vector (e.g. `c(1, 2, 3, 4)`) and R will know what to do with it.\n@fig-vectorization shows how a function conceptually uses vectorization.\n\n![A function using vectorization. Notice how a set of items is included\n*all at once* in the `func()` function and outputs a single item on the\nright. Modified from the [RStudio purrr\ncheatsheet](https://raw.githubusercontent.com/rstudio/cheatsheets/master/purrr.pdf).](/images/vectorization.png){#fig-vectorization\nwidth=\"45%\"}\n\nFor example, in R, there is a vectorized function called `sum()` that\ntakes the entire vector of `values` and outputs the total sum, without\nneeding a for loop.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvalues <- 1:10\n# Vectorized\nsum(values)\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> [1] 55\n```\n:::\n:::\n\n\nAs a comparison, in other programming languages, if you wanted to\ncalculate the sum you would need a loop:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntotal_sum <- 0\n# a vector\nvalues <- 1:10\nfor (value in values) {\n  total_sum <- value + total_sum\n}\ntotal_sum\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> [1] 55\n```\n:::\n:::\n\n\n::: {.callout-note appearance=\"minimal\" collapse=\"true\"}\n## Instructor note\n\nEmphasize this next paragraph.\n:::\n\nWriting effective and proper for loops is actually quite tricky and\ndifficult to easily explain. Because of this and because there are\nbetter and easier ways of writing R code to replace for loops, we will\n**not** be covering loops in this course.\n\nA functional on the other hand is a function that can also use a\nfunction as one of its arguments. @fig-functionals shows how the\nfunctional `map()` from the `{purrr}` package works by taking a vector\n(or list), applying a function to each of those items, and outputting\nthe results from each function. The name `map()` doesn't mean a\ngeographic map, it is the mathematical meaning of map: To use a function\non each item in a set of items.\n\n![A functional that uses a function to apply it to each item in a\nvector. Notice how each of the green coloured boxes are placed into the\n`func()` function and outputs the same number of blue boxes as there are\ngreen boxes. Modified from the [RStudio purrr\ncheatsheet](https://raw.githubusercontent.com/rstudio/cheatsheets/master/purrr.pdf).](/images/functionals.png){#fig-functionals\nwidth=\"90%\"}\n\nHere's a simple toy example to show how it works. We'll use `paste()` on\neach item of `1:5`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(purrr)\nmap(1:5, paste)\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> [[1]]\n#> [1] \"1\"\n#> \n#> [[2]]\n#> [1] \"2\"\n#> \n#> [[3]]\n#> [1] \"3\"\n#> \n#> [[4]]\n#> [1] \"4\"\n#> \n#> [[5]]\n#> [1] \"5\"\n```\n:::\n:::\n\n\nYou'll notice that `map()` outputs a list, with all the `[[1]]` printed.\n`map()` will always output a list. Also notice that the `paste()`\nfunction is given *without* the `()` brackets. Without the brackets, the\nfunction can be used by the `map()` functional and treated like any\nother object in R.\n\nLet's say we wanted to paste together the number with the sentence\n\"seconds have passed\". Normally it would look like:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npaste(1, \"seconds have passed\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> [1] \"1 seconds have passed\"\n```\n:::\n\n```{.r .cell-code}\npaste(2, \"seconds have passed\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> [1] \"2 seconds have passed\"\n```\n:::\n\n```{.r .cell-code}\npaste(3, \"seconds have passed\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> [1] \"3 seconds have passed\"\n```\n:::\n\n```{.r .cell-code}\npaste(4, \"seconds have passed\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> [1] \"4 seconds have passed\"\n```\n:::\n\n```{.r .cell-code}\npaste(5, \"seconds have passed\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> [1] \"5 seconds have passed\"\n```\n:::\n:::\n\n\nOr as a loop:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor (num in 1:5) {\n  sec_passed <- paste(num, \"seconds have passed\")\n  print(sec_passed)\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> [1] \"1 seconds have passed\"\n#> [1] \"2 seconds have passed\"\n#> [1] \"3 seconds have passed\"\n#> [1] \"4 seconds have passed\"\n#> [1] \"5 seconds have passed\"\n```\n:::\n:::\n\n\nWith `map()`, we'd do this a bit differently. `{purrr}` allows us to\ncreate anonymous functions (functions that are used once and disappear\nafter usage) to extend its capabilities. Anonymous functions are created\nby writing `function(x)` (the short version is `\\(x)`), followed by the\nfunction definition inside of `map()`. Using `map()` with an anonymous\nfunction allows us to do more things to the input vector (e.g. `1:5`).\nHere is an example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmap(1:5, function(x) paste(x, \"seconds have passed\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> [[1]]\n#> [1] \"1 seconds have passed\"\n#> \n#> [[2]]\n#> [1] \"2 seconds have passed\"\n#> \n#> [[3]]\n#> [1] \"3 seconds have passed\"\n#> \n#> [[4]]\n#> [1] \"4 seconds have passed\"\n#> \n#> [[5]]\n#> [1] \"5 seconds have passed\"\n```\n:::\n\n```{.r .cell-code}\n# Or with the short version\nmap(1:5, \\(x) paste(x, \"seconds have passed\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> [[1]]\n#> [1] \"1 seconds have passed\"\n#> \n#> [[2]]\n#> [1] \"2 seconds have passed\"\n#> \n#> [[3]]\n#> [1] \"3 seconds have passed\"\n#> \n#> [[4]]\n#> [1] \"4 seconds have passed\"\n#> \n#> [[5]]\n#> [1] \"5 seconds have passed\"\n```\n:::\n:::\n\n\n`{purrr}` supports the use of a syntax shortcut to write anonymous\nfunctions. This shortcut is using `~` (tilde) to start the function and\n`.x` as the replacement for the vector item. `.x` is used instead of `x`\nin order to avoid potential name collisions in functions where `x` is an\nfunction argument (for example in `ggplot2::aes()`, where `x` can be\nused to define the x-axis mapping for a graph). Here is the same example\nas above, now using the `~` shortcut:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmap(1:5, ~ paste(.x, \"seconds have passed\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> [[1]]\n#> [1] \"1 seconds have passed\"\n#> \n#> [[2]]\n#> [1] \"2 seconds have passed\"\n#> \n#> [[3]]\n#> [1] \"3 seconds have passed\"\n#> \n#> [[4]]\n#> [1] \"4 seconds have passed\"\n#> \n#> [[5]]\n#> [1] \"5 seconds have passed\"\n```\n:::\n:::\n\n\nThis is the basics of using functionals. Functions, vectorization, and\nfunctionals provide expressive and powerful approaches to a simple task:\n*Doing an action on each item in a set of items*. And while technically\nusing a for loop lets you \"not repeat yourself\", they tend to be more\nerror prone and harder to write and read compared to these other tools.\nFor some alternative explanations of this, see\n@sec-alternative-loop-explanation.\n:::\n\nBut what does functionals have to do with what we are doing now? Well,\nour `import_user_info()` function only takes in one data file. But we\nhave 22 files that we could load all at once if we used functionals.\n\nThe first thing we have to do is add `library(purrr)` to the `setup`\ncode chunk in the `doc/learning.qmd` document. Then we need to add the\npackage dependency by going to the **Console** and running:\n\n``` r\nusethis::use_package(\"purrr\")\n```\n\nThen, the next step for using the `map()` functional is to get a vector\nor list of all the dataset files available to us. We will return to\nusing the `{fs}` package, which has a function called `dir_ls()` that\nfinds files of a certain pattern. In our case, the pattern is\n`user_info.csv`. So, let's add `library(fs)` to the `setup` code chunk.\nThen, go to the bottom of the `doc/learning.qmd` document, create a new\nheader called `## Using map`, and create a code chunk below that with\n\n{{< var keybind.chunk >}}\n\n\n\nThe `dir_ls()` function takes the path that we want to search\n(`data-raw/mmash/`), uses the argument `regexp` (short for [regular\nexpression](https://r4ds.had.co.nz/strings.html#matching-patterns-with-regular-expressions)\nor also `regex`) to find the pattern, and `recurse` to look in all\nsubfolders. We'll cover regular expressions more in the next session.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nuser_info_files <- dir_ls(here(\"data-raw/mmash/\"),\n  regexp = \"user_info.csv\",\n  recurse = TRUE\n)\n```\n:::\n\n\nThen let's see what the output looks like. For the website, we are only\nshowing the first 3 files. Your output will look slightly different from\nthis.\n\n``` r\nuser_info_files\n```\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> data-raw/mmash/user_1/user_info.csv\n#> data-raw/mmash/user_10/user_info.csv\n#> data-raw/mmash/user_11/user_info.csv\n```\n:::\n:::\n\n\nAlright, we now have all the files ready to give to `map()`. So let's\ntry it!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nuser_info_list <- map(user_info_files, import_user_info)\n```\n:::\n\n\nRemember, that `map()` always outputs a list, so when we look into this\nobject, it will give us 22 tibbles (data.frames). Here we'll only show\nthe first one:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nuser_info_list[[1]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> # A tibble: 1 × 4\n#>   gender weight height   age\n#>   <chr>   <dbl>  <dbl> <dbl>\n#> 1 M          65    169    29\n```\n:::\n:::\n\n\nThis is great because with one line of code we imported all these\ndatasets! But we're missing an important bit of information: The user\nID. A powerful feature of the `{purrr}` package is that it has other\nfunctions to make working with functionals easier. We know `map()`\nalways outputs a list. What if you want to output a character vector\ninstead? If we check the help:\n\n``` r\n?map\n```\n\n::: {.callout-note appearance=\"minimal\" collapse=\"true\"}\n## Instructor note\n\nGo through this help documentation and talk a bit about it.\n:::\n\nWe see that there are other functions, including a function called\n`map_chr()` that seems to output a character vector. There are several\nothers that give an output based on the ending of `map_`, such as:\n\n-   `map_int()` outputs an integer.\n-   `map_dbl()` outputs a numeric value, called a \"double\" in\n    programming.\n-   `map_dfr()` outputs a data frame, combining the list items by row\n    (`r`).\n-   `map_dfc()` outputs a data frame, combining the list items by column\n    (`c`).\n\nThe `map_dfr()` looks like the one we want, since we want all these\ndatasets together as one. If we look at the help for it, we see that it\nhas an argument `.id`, which we can use to create a new column that sets\nthe user ID, or in this case, the file path to the dataset, which has\nthe user ID information in it. So, let's use it and create a new column\ncalled `file_path_id`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nuser_info_df <- map_dfr(user_info_files, import_user_info,\n  .id = \"file_path_id\"\n)\n```\n:::\n\n\nYour `file_path_id` variable will look different. Don't worry, we're\ngoing to tidy up the `file_path_id` variable later.\n\n``` r\nuser_info_df\n```\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> # A tibble: 22 × 5\n#>    file_path_id                         gender weight height   age\n#>    <chr>                                <chr>   <dbl>  <dbl> <dbl>\n#>  1 data-raw/mmash/user_1/user_info.csv  M          65    169    29\n#>  2 data-raw/mmash/user_10/user_info.csv M          85    180    27\n#>  3 data-raw/mmash/user_11/user_info.csv M         115    186    27\n#>  4 data-raw/mmash/user_12/user_info.csv M          67    170    27\n#>  5 data-raw/mmash/user_13/user_info.csv M          74    180    25\n#>  6 data-raw/mmash/user_14/user_info.csv M          64    171    27\n#>  7 data-raw/mmash/user_15/user_info.csv M          80    180    24\n#>  8 data-raw/mmash/user_16/user_info.csv M          67    176    27\n#>  9 data-raw/mmash/user_17/user_info.csv M          60    175    24\n#> 10 data-raw/mmash/user_18/user_info.csv M          80    180     0\n#> # ℹ 12 more rows\n```\n:::\n:::\n\n\nNow that we have this working, let's **add and commit** the changes to\nthe Git history, by using {{< var keybind.git >}}\n\n## Exercise: Brainstorm and discuss how you'd use functionals in your work\n\n> Time: 10 minutes.\n\nAs a group, discuss if you've ever used for loops or functionals like\n`map()` and your experiences with either. Discuss any advantages to\nusing for loops over functionals and vice versa. Then, brainstorm and\ndiscuss as many ways as you can for how you might incorporate\nfunctionals like `map()`, or replace for loops with them, into your own\nwork. Afterwards, groups will briefly share some of what they thought of\nbefore we move on to the next exercise.\n\n## Exercise: Make a function for importing other datasets with functionals {#sec-ex-function-import-all-data}\n\n> Time: 25 minutes.\n\nWe need to do basically the exact same thing for the `saliva.csv`,\n`RR.csv`, and `Actigraph.csv` datasets, following this format:\n\n``` r\nuser_info_files <- dir_ls(here(\"data-raw/mmash/\"), \n                          regexp = \"user_info.csv\", \n                          recurse = TRUE)\nuser_info_df <- map_dfr(user_info_files, import_user_info,\n                        .id = \"file_path_id\")\n```\n\nFor importing the other datasets, we have to modify the code in two\nlocations to get this code to import the other datasets: at the\n`regexp =` argument and at `import_user_info`. This is the perfect\nchance to make a function that you can use for other purposes and that\nis itself a functional (since it takes a function as an input). So\ninside `doc/learning.qmd`, convert this bit of code into a function that\nworks to import the other three datasets.\n\n1.  Create a new header `## Exercise: Map on the other datasets` at the\n    bottom of the document.\n2.  Create a new code chunk below it, using {{< var keybind.chunk >}}.\n3.  Repeat the steps you've taken previously to create a new function:\n    -   Wrap the code with `function() { ... }`\n    -   Name the function `import_multiple_files`\n    -   Within `function()`, set two new arguments called `file_pattern`\n        and `import_function`.\n    -   Within the code, replace and re-write `\"user_info.csv\"` with\n        `file_pattern` (this is *without* quotes around it) and\n        `import_user_info` with `import_function` (also *without*\n        quotes).\n    -   Create generic intermediate objects (instead of\n        `user_info_files` and `user_info_df`). So, replace and re-write\n        `user_info_file` with `data_files` and `user_info_df` with\n        `combined_data`.\n    -   Use `return(combined_data)` at the end of the function to output\n        the imported data frame.\n    -   Create and write Roxygen documentation to describe the new\n        function by using {{< var keybind.roxygen >}}.\n    -   Append `packagename::` to the individual functions (there are\n        three packages used: `{fs}`, `{here}`, and `{purrr}`)\n    -   Run it and check that it works on `saliva.csv`.\n4.  After it works, cut and paste the function into the `R/functions.R`\n    file. Then restart the R session with {{< var keybind.restart-r >}},\n    run the line with `source(here(\"R/functions.R\"))` or with\n    {{< var keybind.source >}}, and test the code out in the\n    **Console**.\n5.  Run `{styler}` while in the `R/functions.R` file with\n    {{< var keybind.styler >}}.\n6.  Once done, **add** the changes you've made and **commit** them to\n    the Git history, using {{< var keybind.git >}}.\n\nUse this code as a guide to help complete this exercise:\n\n``` r\n___ <- ___(___, ___) {\n    ___ <- ___dir_ls(___here(\"data-raw/mmash/\"),\n                     regexp = ___,\n                     recurse = TRUE)\n    \n    ___ <- ___map_dfr(___, ___, \n                      .id = \"file_path_id\")\n    ___(___)\n}\n```\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"**Click for the solution**. Only click if you are struggling or are out of time.\"}\n#' Import multiple MMASH data files and merge into one data frame.\n#'\n#' @param file_pattern Pattern for which data file to import.\n#' @param import_function Function to import the data file.\n#'\n#' @return A single data frame/tibble.\n#'\nimport_multiple_files <- function(file_pattern, import_function) {\n  data_files <- fs::dir_ls(here::here(\"data-raw/mmash/\"),\n    regexp = file_pattern,\n    recurse = TRUE\n  )\n\n  combined_data <- purrr::map_dfr(data_files, import_function,\n    .id = \"file_path_id\"\n  )\n  return(combined_data)\n}\n\n# Test on saliva in the Console\nimport_multiple_files(\"saliva.csv\", import_saliva)\n```\n:::\n\n\n## Adding to the processing script and clean up Quart / R Markdown document\n\nWe've now made a function that imports multiple data files based on the\ntype of data file, we can start using this function directly, like we\ndid in the exercise above for the saliva data. We've already imported\nthe `user_info_df` previously, but now we should do some tidying up of\nour Quarto / R Markdown file and to start updating the\n`data-raw/mmash.R` script. Why are we doing that? Because the Quarto / R\nMarkdown file is only a sandbox to test code out and in the end we want\na script that takes the raw data, processes it, and creates a working\ndataset we can use for analysis.\n\nFirst thing we will do is delete **everything** below the `setup` code\nchunk that contains the `library()` and `source()` code. Why do we\ndelete everything? Because it keeps things cleaner and makes it easier\nto look through the file. And because we use Git, nothing is truly gone\nso you can always go back to the text later. Next, we restart the R\nsession with {{< var keybind.restart-r >}}. Then we'll create a new code\nchunk below the `setup` chunk where we will use the\n`import_multiple_files()` function to import the user info and saliva\ndata.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nuser_info_df <- import_multiple_files(\"user_info.csv\", import_user_info)\nsaliva_df <- import_multiple_files(\"saliva.csv\", import_saliva)\n```\n:::\n\n\nTo test that things work, we'll create an HTML document from our Quarto\n/ R Markdown document by using the \"Render\" / \"Knit\" button at the top\nof the pane or with {{< var keybind.render >}}. Once it creates the\nfile, it should either pop up or open in the Viewer pane on the side. If\nit works, then we can move on and open up the `data-raw/mmash.R` script.\nInside the script, copy and paste these two lines of code to the bottom\nof the script. Afterwards, go the top of the script and right below the\n`library(here)` code, add these two lines of code, so it looks like\nthis:\n\n``` r\nlibrary(here)\nlibrary(tidyverse)\nsource(here(\"R/functions.R\"))\n```\n\nSave the files, then add and commit the changes to the Git history with\n{{< var keybind.git >}}.\n\n## Split-apply-combine technique and functionals\n\n::: {.callout-note appearance=\"minimal\" collapse=\"true\"}\n## Instructor note\n\nVerbally cover this section before moving on to the summarizing. Let\nthem know they can read more about this in this section.\n:::\n\nWe're taking a quick detour to briefly talk about a concept that\nperfectly illustrates how vectorization and functionals fit into doing\ndata analysis. The concept is called the\n[split-apply-combine](https://r-cubed-intro.rostools.org/session/wrangling.html#split-apply-combine-summarizing-data)\ntechnique, which we covered in the beginner R course. The method is:\n\n1.  Split the data into groups (e.g. diabetes status).\n2.  Apply some analysis or statistics to each group (e.g. finding the\n    mean of age).\n3.  Combine the results to present them together (e.g. into a data frame\n    that you can use to make a plot or table).\n\nSo when you split data into multiple groups, you make a *vector* that\nyou can than apply (i.e. the *map* functional) some statistical\ntechnique to each group through *vectorization*. This technique works\nreally well for a range of tasks, including for our task of summarizing\nsome of the MMASH data so we can merge it all into one dataset.\n\n## Exercise: What is the pipe?\n\n> Time: 5 minutes.\n\n::: {.callout-note appearance=\"minimal\" collapse=\"true\"}\n## Instructor note\n\nBefore starting this exercise, ask how many have used the pipe before.\nIf everyone has, then move on to the next section. If some haven't, let\nthe others in the group explain, but **do not** use much time or even\ndemonstrate it. If they don't know what it is, they can look it up\nafter. We covered this in the introduction course, so we should not\ncover it again here.\n:::\n\nWe haven't used the `%>%` pipe from the `{magrittr}` package yet, but it\nis used extensively in many R packages and is the foundation of\ntidyverse packages. The function fundamentally changed how people write\nR code so much that in version 4.1 a similar function, `|>`, was added\nto base R. To make sure everyone is aware of what the pipe is, in your\ngroups please do either task:\n\n-   If one or more person in the group doesn't know what the pipe is,\n    take some time to talk about and explain it (if you know).\n-   If no one in the group knows, please read [the section on\n    it](https://r-cubed-intro.rostools.org/sessions/data-management.html#chaining-functions-with-the-pipe)\n    from the beginner course.\n\n## Summarising data through functionals {#sec-summarise-with-functionals}\n\nFunctionals and vectorization are an integral component of how R works\nand they appear throughout many of R's functions and packages. They are\nparticularly used throughout the `{tidyverse}` packages like `{dplyr}`.\nLet's get into some more advanced features of `{dplyr}` functions that\nwork as functionals. Before we continue, re-run the code for getting\n`user_info_df` since you had restarted the R session previously.\n\nSince we're going to use `{dplyr}`, we need to add it as a dependency by\ntyping this in the Console:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nusethis::use_package(\"dplyr\")\n```\n:::\n\n\nThere are many \"verbs\" in `{dplyr}`, like `select()`, `rename()`,\n`mutate()`, `summarise()`, and `group_by()` (covered in more detail in\nthe [Data Management and\nWrangling](https://r-cubed-intro.rostools.org/sessions/data-management.html#managing-and-working-with-data-in-r)\nsession of the beginner course). The common usage of these verbs is\nthrough acting on and directly using the column names (e.g. without `\"`\nquotes around the column name). For instance, to select only the `age`\ncolumn, you would type out:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nuser_info_df %>%\n  select(age)\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> # A tibble: 22 × 1\n#>      age\n#>    <dbl>\n#>  1    29\n#>  2    27\n#>  3    27\n#>  4    27\n#>  5    25\n#>  6    27\n#>  7    24\n#>  8    27\n#>  9    24\n#> 10     0\n#> # ℹ 12 more rows\n```\n:::\n:::\n\n\nBut many `{dplyr}` verbs can also take functions as input. When you\ncombine `select()` with the `where()` function, you can select different\nvariables. The `where()` function is a `tidyselect` helper, a set of\nfunctions that make it easier to select variables. Some additional\nhelper functions are listed in @tbl-tidyselect-helpers.\n\n\n::: {#tbl-tidyselect-helpers .cell tbl-cap='Common tidyselect helper functions and some of their use cases.'}\n::: {.cell-output-display}\n|What it selects                                   |Example                                                       |Function       |\n|:-------------------------------------------------|:-------------------------------------------------------------|:--------------|\n|Select variables where a function returns TRUE    |Select variables that have data as character (`is.character`) |`where()`      |\n|Select all variables                              |Select all variables in `user_info_df`                        |`everything()` |\n|Select variables that contain the matching string |Select variables that contain the string \"user_info\"          |`contains()`   |\n|Select variables that ends with string            |Select all variables that end with \"date\"                     |`ends_with()`  |\n:::\n:::\n\n\nLet's select columns that are numeric:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nuser_info_df %>%\n  select(where(is.numeric))\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> # A tibble: 22 × 3\n#>    weight height   age\n#>     <dbl>  <dbl> <dbl>\n#>  1     65    169    29\n#>  2     85    180    27\n#>  3    115    186    27\n#>  4     67    170    27\n#>  5     74    180    25\n#>  6     64    171    27\n#>  7     80    180    24\n#>  8     67    176    27\n#>  9     60    175    24\n#> 10     80    180     0\n#> # ℹ 12 more rows\n```\n:::\n:::\n\n\nOr, only character columns:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nuser_info_df %>%\n  select(where(is.character))\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> # A tibble: 22 × 2\n#>    file_path_id                         gender\n#>    <chr>                                <chr> \n#>  1 data-raw/mmash/user_1/user_info.csv  M     \n#>  2 data-raw/mmash/user_10/user_info.csv M     \n#>  3 data-raw/mmash/user_11/user_info.csv M     \n#>  4 data-raw/mmash/user_12/user_info.csv M     \n#>  5 data-raw/mmash/user_13/user_info.csv M     \n#>  6 data-raw/mmash/user_14/user_info.csv M     \n#>  7 data-raw/mmash/user_15/user_info.csv M     \n#>  8 data-raw/mmash/user_16/user_info.csv M     \n#>  9 data-raw/mmash/user_17/user_info.csv M     \n#> 10 data-raw/mmash/user_18/user_info.csv M     \n#> # ℹ 12 more rows\n```\n:::\n:::\n\n\nLikewise, with functions like `summarise()`, if you want to for example\ncalculate the mean of cortisol in the saliva dataset, you would usually\ntype out:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsaliva_df %>%\n  summarise(cortisol_mean = mean(cortisol_norm))\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> # A tibble: 1 × 1\n#>   cortisol_mean\n#>           <dbl>\n#> 1        0.0490\n```\n:::\n:::\n\n\nIf you want to calculate the mean of multiple columns, you might think\nyou'd have to do something like:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsaliva_df %>%\n  summarise(\n    cortisol_mean = mean(cortisol_norm),\n    melatonin_mean = mean(melatonin_norm)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> # A tibble: 1 × 2\n#>   cortisol_mean melatonin_mean\n#>           <dbl>          <dbl>\n#> 1        0.0490  0.00000000765\n```\n:::\n:::\n\n\nBut instead, there is the `across()` function that works like `map()`\nand allows you to calculate the mean across which ever columns you want.\nIn many ways, `across()` is a duplicate of `map()`, particularly in the\narguments you give it.\n\n::: callout-note\n## Reading task: \\~2 minutes\n\nWhen you look in `?across`, there are two main arguments and one\noptional one (plus one deprecated one):\n\n1.  `.cols` argument: Columns you want to use.\n    -   Write column names directly and wrapped in `c()`:\n        `c(age, weight)`.\n    -   Write `tidyselect` helpers: `everything()`, `starts_with()`,\n        `contains()`, `ends_with()`\n    -   Use a function wrapped in `where()`: `where(is.numeric)`,\n        `where(is.character)`\n2.  `.fns`: The function to use on the `.cols`.\n    -   A bare function (`mean`) applies it to each column and returns\n        the output, with the column name unchanged.\n\n    -   A list with bare functions (`list(mean, sd)`) applies each\n        function to each column and returns the output with the column\n        name appended with a number (e.g. `cortisol_norm_1`).\n\n    -   An anonymous function passed with either `~` (using `.x` to\n        refer to the variable) or `\\()` or `function()` like in `map()`.\n        For instance, these three lines of code below mean all the same\n        and are used to say \"put age and weight, one after the other, in\n        place of where `.x` is located\" to calculate the mean for age\n        and the mean for weight.\n\n        ``` r\n        across(c(age, weight), ~ mean(.x, na.rm = TRUE))\n        across(c(age, weight), function(x) mean(x, na.rm = TRUE))\n        across(c(age, weight), \\(x) mean(x, na.rm = TRUE))\n        ```\n\n    -   A named list with bare or anonymous functions\n        (`list(average = mean, stddev = sd)`) does the same as above but\n        instead returns an output with the column names appended with\n        the name given to the function in the list (e.g.\n        `cortisol_norm_average`). You can also use anonymous functions\n        within the list:\n\n        ``` r\n        list(\n          average = ~ mean(.x, na.rm = TRUE),\n          stddev = ~ sd(.x, na.rm = TRUE),\n        )\n        ```\n3.  `...` argument (**deprecated**): Arguments to give to the functions\n    in `.fns`. No longer used.\n4.  `.names` argument: Customize the output of the column names. We\n    won't cover this argument.\n:::\n\n::: {.callout-note appearance=\"minimal\" collapse=\"true\"}\n## Instructor note\n\nGo over the first two arguments again, reinforcing what they read.\n:::\n\nLet's try out some examples. To calculate the mean of `cortisol_norm`\nlike we did above, we'd do:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsaliva_df %>%\n  summarise(across(cortisol_norm, mean))\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> # A tibble: 1 × 1\n#>   cortisol_norm\n#>           <dbl>\n#> 1        0.0490\n```\n:::\n:::\n\n\nTo calculate the mean of another column:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsaliva_df %>%\n  summarise(across(c(cortisol_norm, melatonin_norm), mean))\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> # A tibble: 1 × 2\n#>   cortisol_norm melatonin_norm\n#>           <dbl>          <dbl>\n#> 1        0.0490  0.00000000765\n```\n:::\n:::\n\n\nThis is nice, but changing the column names so that the function name is\nadded would make reading what the column contents are clearer. That's\nwhen we would use \"named lists\", which are lists that look like:\n\n``` r\nlist(item_one_name = ..., item_two_name = ...)\n```\n\nSo, for having a named list with mean inside `across()`, it would look\nlike:\n\n``` r\nlist(mean = mean)\n# or\nlist(average = mean)\n# or\nlist(ave = mean)\n```\n\nYou can confirm that it is a list by using the function `names()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(list(mean = mean))\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> [1] \"mean\"\n```\n:::\n\n```{.r .cell-code}\nnames(list(average = mean))\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> [1] \"average\"\n```\n:::\n\n```{.r .cell-code}\nnames(list(ave = mean))\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> [1] \"ave\"\n```\n:::\n:::\n\n\nLet's stick with `list(mean = mean)`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsaliva_df %>%\n  summarise(across(cortisol_norm, list(mean = mean)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> # A tibble: 1 × 1\n#>   cortisol_norm_mean\n#>                <dbl>\n#> 1             0.0490\n```\n:::\n:::\n\n\nIf we wanted to do that for all numeric columns and also calculate\n`sd()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsaliva_df %>%\n  summarise(across(where(is.numeric), list(mean = mean, sd = sd)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> # A tibble: 1 × 4\n#>   cortisol_norm_mean cortisol_norm_sd melatonin_norm_mean\n#>                <dbl>            <dbl>               <dbl>\n#> 1             0.0490           0.0478       0.00000000765\n#> # ℹ 1 more variable: melatonin_norm_sd <dbl>\n```\n:::\n:::\n\n\nWe can use these concepts and code to process the other longer datasets,\nlike `RR.csv`, in a way that makes it more meaningful to eventually\nmerge (also called \"join\") them with the smaller datasets like\n`user_info.csv` or `saliva.csv`. Let's work with the `RR.csv` dataset to\neventually join it with the others.\n\n## Summarizing long data like the RR dataset\n\nWith the RR dataset, each participant had almost 100,000 data points\nrecorded over two days of collection. So if we want to join with the\nother datasets, we need to calculate summary measures by at least\n`file_path_id` and also preferably by `day` as well. In this case, we\nneed to `group_by()` these two variables before summarising that lets us\nuse the split-apply-combine technique. Let's first summarise by taking\nthe mean of `ibi_s` (which is the inter-beat interval in seconds):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrr_df <- import_multiple_files(\"RR.csv\", import_rr)\nrr_df %>%\n  group_by(file_path_id, day) %>%\n  summarise(across(ibi_s, list(mean = mean)))\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\n#> `summarise()` has grouped output by 'file_path_id'. You can\n#> override using the `.groups` argument.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> # A tibble: 44 × 3\n#>    file_path_id                    day ibi_s_mean\n#>    <chr>                         <dbl>      <dbl>\n#>  1 data-raw/mmash/user_1/RR.csv      1      0.666\n#>  2 data-raw/mmash/user_1/RR.csv      2      0.793\n#>  3 data-raw/mmash/user_10/RR.csv     1      0.820\n#>  4 data-raw/mmash/user_10/RR.csv     2      0.856\n#>  5 data-raw/mmash/user_11/RR.csv     1      0.818\n#>  6 data-raw/mmash/user_11/RR.csv     2      0.923\n#>  7 data-raw/mmash/user_12/RR.csv     1      0.779\n#>  8 data-raw/mmash/user_12/RR.csv     2      0.883\n#>  9 data-raw/mmash/user_13/RR.csv     1      0.727\n#> 10 data-raw/mmash/user_13/RR.csv     2      0.953\n#> # ℹ 34 more rows\n```\n:::\n:::\n\n\nWhile there are no missing values here, let's add the argument\n`na.rm = TRUE` just in case. In order add this argument to the mean, we\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrr_df %>%\n  group_by(file_path_id, day) %>%\n  summarise(across(ibi_s, list(mean = ~ mean(.x, na.rm = TRUE))))\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\n#> `summarise()` has grouped output by 'file_path_id'. You can\n#> override using the `.groups` argument.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> # A tibble: 44 × 3\n#>    file_path_id                    day ibi_s_mean\n#>    <chr>                         <dbl>      <dbl>\n#>  1 data-raw/mmash/user_1/RR.csv      1      0.666\n#>  2 data-raw/mmash/user_1/RR.csv      2      0.793\n#>  3 data-raw/mmash/user_10/RR.csv     1      0.820\n#>  4 data-raw/mmash/user_10/RR.csv     2      0.856\n#>  5 data-raw/mmash/user_11/RR.csv     1      0.818\n#>  6 data-raw/mmash/user_11/RR.csv     2      0.923\n#>  7 data-raw/mmash/user_12/RR.csv     1      0.779\n#>  8 data-raw/mmash/user_12/RR.csv     2      0.883\n#>  9 data-raw/mmash/user_13/RR.csv     1      0.727\n#> 10 data-raw/mmash/user_13/RR.csv     2      0.953\n#> # ℹ 34 more rows\n```\n:::\n:::\n\n\nYou might notice a message (depending on the version of `{dplyr}` you\nhave):\n\n```         \n`summarise()` regrouping output by 'file_path_id' (override with `.groups` argument)\n```\n\n::: callout-note\n## Reading task: \\~5 minutes\n\nThis message talks about regrouping, and overriding based on the\n`.groups` argument. If we look in the help `?summarise`, at the\n`.groups` argument, we see that this argument is currently\n\"experimental\". At the bottom there is a message about:\n\n> In addition, a message informs you of that choice, unless the option\n> \"dplyr.summarise.inform\" is set to FALSE, or when summarise() is\n> called from a function in a package.\n\nSo how would be go about removing this message? By putting the\n\"dplyr.summarise.inform\" in the `options()` function. So, go to the\n`setup` code chunk at the top of the document and add this code to the\ntop:\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(dplyr.summarise.inform = FALSE)\n```\n:::\n\n\nYou will now no longer get the message.\n:::\n\nLet's also add standard deviation as another measure from the RR\ndatasets:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarised_rr_df <- rr_df %>%\n  group_by(file_path_id, day) %>%\n  summarise(across(ibi_s, list(\n    mean = ~ mean(.x, na.rm = TRUE),\n    sd = ~ sd(.x, na.rm = TRUE)\n  )))\nsummarised_rr_df\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> # A tibble: 44 × 4\n#>    file_path_id                    day ibi_s_mean ibi_s_sd\n#>    <chr>                         <dbl>      <dbl>    <dbl>\n#>  1 data-raw/mmash/user_1/RR.csv      1      0.666   0.164 \n#>  2 data-raw/mmash/user_1/RR.csv      2      0.793   0.194 \n#>  3 data-raw/mmash/user_10/RR.csv     1      0.820   0.225 \n#>  4 data-raw/mmash/user_10/RR.csv     2      0.856   0.397 \n#>  5 data-raw/mmash/user_11/RR.csv     1      0.818   0.137 \n#>  6 data-raw/mmash/user_11/RR.csv     2      0.923   0.182 \n#>  7 data-raw/mmash/user_12/RR.csv     1      0.779   0.0941\n#>  8 data-raw/mmash/user_12/RR.csv     2      0.883   0.258 \n#>  9 data-raw/mmash/user_13/RR.csv     1      0.727   0.147 \n#> 10 data-raw/mmash/user_13/RR.csv     2      0.953   0.151 \n#> # ℹ 34 more rows\n```\n:::\n:::\n\n\nWhenever you are finished with a grouping effect, it's good practice to\nend the `group_by()` with `ungroup()`. Let's add it to the end:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummarised_rr_df <- rr_df %>%\n  group_by(file_path_id, day) %>%\n  summarise(across(ibi_s, list(\n    mean = ~ mean(.x, na.rm = TRUE),\n    sd = ~ sd(.x, na.rm = TRUE)\n  ))) %>%\n  ungroup()\nsummarised_rr_df\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```{.sourceCode}\n#> # A tibble: 44 × 4\n#>    file_path_id                    day ibi_s_mean ibi_s_sd\n#>    <chr>                         <dbl>      <dbl>    <dbl>\n#>  1 data-raw/mmash/user_1/RR.csv      1      0.666   0.164 \n#>  2 data-raw/mmash/user_1/RR.csv      2      0.793   0.194 \n#>  3 data-raw/mmash/user_10/RR.csv     1      0.820   0.225 \n#>  4 data-raw/mmash/user_10/RR.csv     2      0.856   0.397 \n#>  5 data-raw/mmash/user_11/RR.csv     1      0.818   0.137 \n#>  6 data-raw/mmash/user_11/RR.csv     2      0.923   0.182 \n#>  7 data-raw/mmash/user_12/RR.csv     1      0.779   0.0941\n#>  8 data-raw/mmash/user_12/RR.csv     2      0.883   0.258 \n#>  9 data-raw/mmash/user_13/RR.csv     1      0.727   0.147 \n#> 10 data-raw/mmash/user_13/RR.csv     2      0.953   0.151 \n#> # ℹ 34 more rows\n```\n:::\n:::\n\n\nUngrouping the data with `ungroup()` does not provide any visual\nindication of what is happening. However, in the background, it removes\ncertain metadata that the `group_by()` function added.\n\nBefore continuing, let's run `{styler}` with {{< var keybind.styler >}}\nand knit the Quarto / R Markdown document with\n{{< var keybind.render >}} to confirm that everything runs as it should.\nIf the knitting works, then switch to the Git interface and **add and\ncommit** the changes so far with {{< var keybind.git >}}.\n\n## Exercise: Summarise the Actigraph data\n\n> Time: 15 minutes.\n\nLike with the `RR.csv` dataset, let's process the `Actigraph.csv`\ndataset so that it makes it easier to join with the other datasets\nlater. Make sure to read the warning block below.\n\n1.  Like usual, create a new Markdown header called e.g.\n    `## Exercise: Summarise  Actigraph` and insert a new code chunk\n    below that with {{< var keybind.chunk >}}.\n2.  Import all the Actigraph data files using the\n    `import_multiple_files()` function you created previously. Name the\n    new data frame `actigraph_df`.\n3.  Look into the [Data\n    Description](https://physionet.org/content/mmash/1.0.0/) to find out\n    what each column is for.\n4.  Based on the documentation, which variables would you be most\n    interested in analyzing more?\n5.  Decide which summary measure(s) you think may be most interesting\n    for you (e.g. `median()`, `sd()`, `mean()`, `max()`, `min()`,\n    `var()`).\n6.  Use `group_by()` of `file_path_id` and `day`, then use `summarise()`\n    with `across()` to summarise the variables you are interested in\n    (from item 4 above) with the summary functions you chose. Assign the\n    newly summarised data frame to a new data frame and call it\n    `summarised_actigraph_df`.\n7.  End the grouping effect with `ungroup()`.\n8.  Run `{styler}` while in the `doc/learning.qmd` file with\n    {{< var keybind.styler >}}.\n9.  Knit the `doc/learning.qmd` document with {{< var keybind.render >}}\n    to make sure everything works.\n10. **Add and commit** the changes you've made into the Git history with\n    {{< var keybind.git >}}.\n\n::: {.callout-warning appearance=\"default\"}\nSince the `actigraph_df` dataset is quite large, we **strongly**\nrecommend not using `View()` or selecting the dataframe in the\nEnvironments pane to view it. For many computers, your R session will\n**crash**! Instead type out `glimpse(actigraph_df)` or simply\n`actigraph_df` in the Console.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"**Click for the solution**. Only click if you are struggling or are out of time.\"}\nactigraph_df <- import_multiple_files(\"Actigraph.csv\", import_actigraph)\nsummarised_actigraph_df <- actigraph_df %>%\n  group_by(file_path_id, day) %>%\n  # These statistics will probably be different for you\n  summarise(across(hr, list(\n    mean = ~ mean(.x, na.rm = TRUE),\n    sd = ~ sd(.x, na.rm = TRUE)\n  ))) %>%\n  ungroup()\n```\n:::\n\n\n## Cleaning up and adding to the processing script\n\n**We'll do this all together**. We've tested out, imported, and\nprocessed two new datasets, the RR and the Actigraph datasets. First, in\nthe R Markdown / Quarto document, cut the code that we used to import\nand process the `rr_df` and `actigraph_df` data. Then open up the\n`data-raw/mmash.R` file and paste the cut code into the bottom of the\nscript. It should look something like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nuser_info_df <- import_multiple_files(\"user_info.csv\", import_user_info)\nsaliva_df <- import_multiple_files(\"saliva.csv\", import_saliva)\nrr_df <- import_multiple_files(\"RR.csv\", import_rr)\nactigraph_df <- import_multiple_files(\"Actigraph.csv\", import_actigraph)\n\nsummarised_rr_df <- rr_df %>%\n  group_by(file_path_id, day) %>%\n  summarise(across(ibi_s, list(\n    mean = ~ mean(.x, na.rm = TRUE),\n    sd = ~ sd(.x, na.rm = TRUE)\n  ))) %>%\n  ungroup()\n\n# Code pasted here that was made from the above exercise\n```\n:::\n\n\nNext, go to the R Markdown / Quarto document and again delete\n**everything** below the `setup` code chunk. After it has been deleted,\nadd and commit the changes to the Git history with\n{{< var keybind.git >}}.\n\n## Summary\n\n-   R is a functional programming language:\n    -   It uses functions that take an input, do an action, and give an\n        output.\n    -   It uses vectorisation that apply a function to multiple items\n        (in a vector) all at once rather than using loops.\n    -   It uses functionals that allow functions to use other functions\n        as input.\n-   Use the `{purrr}` package and its function `map()` when you want to\n    repeat a function on multiple items at once.\n-   Use `group_by()`, `summarise()`, and `across()` followed by\n    `ungroup()` to use the split-apply-combine technique when needing to\n    do an action on groups within the data (e.g. calculate the mean age\n    between education groups).\n\n\n\n",
    "supporting": [
      "functionals_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}